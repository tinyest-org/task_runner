//! Task Runner HTTP Server
//!
//! A service for orchestrating task execution with DAG dependencies,
//! concurrency control, and webhook-based actions.

use mimalloc::MiMalloc;
use std::sync::Arc;

#[global_allocator]
static GLOBAL: MiMalloc = MiMalloc;

use actix_web::{App, HttpServer, web};
use actix_web_prometheus::PrometheusMetricsBuilder;
use diesel::{Connection, PgConnection};
use task_runner::{
    DbPool,
    action::{ActionContext, ActionExecutor},
    circuit_breaker::{CircuitBreaker, CircuitBreakerConfig},
    config::Config,
    handlers::{self, AppState},
    initialize_db_pool, metrics,
    tracing::{TracingConfig, init_tracing, shutdown_tracing},
    validation,
    workers::UpdateEvent,
};
use tokio::sync::{mpsc, watch};

use diesel_migrations::MigrationHarness;
use diesel_migrations::{EmbeddedMigrations, embed_migrations};
pub const MIGRATIONS: EmbeddedMigrations = embed_migrations!("migrations");

#[actix_web::main]
async fn main() -> std::io::Result<()> {
    dotenvy::dotenv().ok();

    // Initialize distributed tracing (before env_logger if enabled)
    let tracing_config = TracingConfig::from_env();
    let tracer_provider = if tracing_config.enabled {
        init_tracing(&tracing_config)
    } else {
        env_logger::init_from_env(env_logger::Env::new().default_filter_or("info"));
        None
    };

    let config = Arc::new(load_config());

    log::info!("Starting HTTP server at http://0.0.0.0:{}", config.port);
    log::info!("Using public url {}", &config.host_url);

    init_security(&config);

    rustls::crypto::ring::default_provider()
        .install_default()
        .expect("Failed to install rustls crypto provider");

    let pool = initialize_db_pool(&config.pool).await;
    log::info!("Database pool initialized");

    run_migrations(&config.database_url);

    let (sender, receiver) = mpsc::channel::<UpdateEvent>(config.worker.batch_channel_capacity);
    let (shutdown_tx, shutdown_rx) = watch::channel(false);

    let circuit_breaker = create_circuit_breaker(&config);
    let action_context = Arc::new(new_action_executor(&config));

    let app_data = AppState {
        pool: pool.clone(),
        sender,
        action_executor: new_action_executor(&config),
        config: config.clone(),
        circuit_breaker,
    };

    let workers = spawn_workers(&pool, &action_context, &config, receiver, &shutdown_rx);

    metrics::init_metrics();
    let prometheus = PrometheusMetricsBuilder::new("api")
        .endpoint("/metrics")
        .registry(metrics::REGISTRY.clone())
        .build()
        .unwrap();

    let port = config.port;

    let server_result = HttpServer::new(move || {
        App::new()
            .app_data(web::Data::new(app_data.clone()))
            .wrap(prometheus.clone())
            .configure(handlers::configure_routes)
    })
    .bind(("0.0.0.0", port))?
    .shutdown_timeout(30)
    .run()
    .await;

    // Graceful shutdown
    log::info!("HTTP server stopped, signaling workers to shut down");
    let _ = shutdown_tx.send(true);
    workers.join(std::time::Duration::from_secs(10)).await;
    log::info!("All workers shut down");

    shutdown_tracing(tracer_provider);

    server_result
}

// =============================================================================
// Initialization helpers
// =============================================================================

fn load_config() -> Config {
    let config = Config::from_env().unwrap_or_else(|e| {
        log::error!("Configuration error: {}", e);
        std::process::exit(1);
    });
    log::info!("Configuration loaded successfully");
    config
}

fn init_security(config: &Config) {
    validation::init_security_config(config.security.clone());
    if config.security.skip_ssrf_validation {
        log::warn!("SSRF validation is disabled - this should only be used in development!");
    }
}

fn run_migrations(database_url: &str) {
    let mut conn = PgConnection::establish(database_url).unwrap_or_else(|e| {
        log::error!("Failed to connect to database for migrations: {}", e);
        std::process::exit(1);
    });
    conn.run_pending_migrations(MIGRATIONS).unwrap_or_else(|e| {
        log::error!("Failed to run migrations: {}", e);
        std::process::exit(1);
    });
    log::info!("Database migrations completed");
}

fn new_action_executor(config: &Config) -> ActionExecutor {
    ActionExecutor::new(ActionContext {
        host_address: config.host_url.clone(),
        webhook_idempotency_timeout: config.worker.claim_timeout,
    })
}

fn create_circuit_breaker(config: &Config) -> Arc<CircuitBreaker> {
    if config.circuit_breaker.enabled {
        log::info!(
            "Circuit breaker enabled with failure_threshold={}, recovery_timeout={}s",
            config.circuit_breaker.failure_threshold,
            config.circuit_breaker.recovery_timeout_secs
        );
        Arc::new(CircuitBreaker::new(CircuitBreakerConfig {
            failure_threshold: config.circuit_breaker.failure_threshold,
            failure_window: std::time::Duration::from_secs(
                config.circuit_breaker.failure_window_secs,
            ),
            recovery_timeout: std::time::Duration::from_secs(
                config.circuit_breaker.recovery_timeout_secs,
            ),
            success_threshold: config.circuit_breaker.success_threshold,
        }))
    } else {
        log::info!("Circuit breaker disabled");
        Arc::new(CircuitBreaker::new(CircuitBreakerConfig {
            failure_threshold: u32::MAX,
            failure_window: std::time::Duration::from_secs(1),
            recovery_timeout: std::time::Duration::from_secs(1),
            success_threshold: 1,
        }))
    }
}

// =============================================================================
// Worker management
// =============================================================================

struct WorkerHandles {
    start: tokio::task::JoinHandle<()>,
    timeout: tokio::task::JoinHandle<()>,
    batch: tokio::task::JoinHandle<()>,
    retention: tokio::task::JoinHandle<()>,
}

impl WorkerHandles {
    async fn join(self, timeout: std::time::Duration) {
        let _ = tokio::time::timeout(timeout, async {
            let _ = self.start.await;
            let _ = self.timeout.await;
            let _ = self.batch.await;
            let _ = self.retention.await;
        })
        .await;
    }
}

fn spawn_workers(
    pool: &DbPool,
    action_executor: &Arc<ActionExecutor>,
    config: &Config,
    receiver: mpsc::Receiver<UpdateEvent>,
    shutdown_rx: &watch::Receiver<bool>,
) -> WorkerHandles {
    let start = {
        let pool = pool.clone();
        let executor = action_executor.clone();
        let interval = config.worker.loop_interval;
        let dead_end_enabled = config.worker.dead_end_cancel_enabled;
        let shutdown = shutdown_rx.clone();
        actix_web::rt::spawn(async move {
            task_runner::workers::start_loop(
                executor.as_ref(),
                pool,
                interval,
                dead_end_enabled,
                shutdown,
            )
            .await;
        })
    };

    let timeout = {
        let pool = pool.clone();
        let executor = action_executor.clone();
        let interval = config.worker.timeout_check_interval;
        let claim_timeout = config.worker.claim_timeout;
        let dead_end_enabled = config.worker.dead_end_cancel_enabled;
        let shutdown = shutdown_rx.clone();
        actix_web::rt::spawn(async move {
            task_runner::workers::timeout_loop(
                executor,
                pool,
                interval,
                claim_timeout,
                dead_end_enabled,
                shutdown,
            )
            .await;
        })
    };

    let batch = {
        let pool = pool.clone();
        let interval = config.worker.batch_flush_interval;
        let shutdown = shutdown_rx.clone();
        actix_web::rt::spawn(async move {
            task_runner::workers::batch_updater(pool, receiver, interval, shutdown).await;
        })
    };

    let retention = {
        let pool = pool.clone();
        let retention_config = config.retention.clone();
        let shutdown = shutdown_rx.clone();
        actix_web::rt::spawn(async move {
            task_runner::workers::retention_cleanup_loop(pool, retention_config, shutdown).await;
        })
    };

    WorkerHandles {
        start,
        timeout,
        batch,
        retention,
    }
}
