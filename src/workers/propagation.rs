use crate::{
    Conn,
    action::ActionExecutor,
    db_operation::{self, DbError},
    metrics,
    models::{StatusKind, Task},
};
use diesel::prelude::*;
use diesel_async::RunQueryDsl;

use super::webhooks::{
    fire_cancel_webhooks, fire_end_webhooks, fire_webhooks_for_canceled_ancestors,
};

/// Propagates task completion to dependent children using batched queries.
///
/// When a parent task completes:
/// 1. If parent failed/canceled: batch-mark all requires_success children as Failure
/// 2. Batch-decrement wait_finished for all remaining children in Waiting status
/// 3. Batch-decrement wait_success for children where parent succeeded AND requires_success
/// 4. Batch-transition children to Pending where both counters reach 0
///
/// Returns the list of all task IDs that were cascade-failed (recursively),
/// so callers can fire on_failure webhooks for them after the transaction commits.
///
/// This uses O(1) queries per propagation level instead of O(N) per child.
#[tracing::instrument(name = "propagate_to_children", level = "debug", skip(conn), fields(parent_id = %parent_id, status = ?result_status))]
pub(crate) async fn propagate_to_children<'a>(
    parent_id: &uuid::Uuid,
    result_status: &StatusKind,
    conn: &mut Conn<'a>,
) -> Result<Vec<uuid::Uuid>, DbError> {
    use crate::schema::link::dsl as link_dsl;
    use crate::schema::task::dsl as task_dsl;

    let parent_succeeded = result_status == &StatusKind::Success;
    let parent_failed =
        result_status == &StatusKind::Failure || result_status == &StatusKind::Canceled;

    // Record dependency propagation metric
    let outcome = if parent_succeeded {
        "success"
    } else {
        "failure"
    };
    metrics::record_dependency_propagation(outcome);

    // Get all children of this parent task
    let children_links: Vec<(uuid::Uuid, bool)> = link_dsl::link
        .filter(link_dsl::parent_id.eq(parent_id))
        .select((link_dsl::child_id, link_dsl::requires_success))
        .load::<(uuid::Uuid, bool)>(conn)
        .await?;

    if children_links.is_empty() {
        return Ok(vec![]);
    }

    // Split children into groups for batched operations
    let mut fail_child_ids: Vec<uuid::Uuid> = Vec::new();
    let mut decrement_child_ids: Vec<uuid::Uuid> = Vec::new();
    let mut decrement_success_child_ids: Vec<uuid::Uuid> = Vec::new();

    for (child_id, requires_success) in &children_links {
        if parent_failed && *requires_success {
            fail_child_ids.push(*child_id);
        } else {
            decrement_child_ids.push(*child_id);
            if parent_succeeded && *requires_success {
                decrement_success_child_ids.push(*child_id);
            }
        }
    }

    // Collect all cascade-failed task IDs (direct + recursive)
    let mut all_cascade_failed: Vec<uuid::Uuid> = Vec::new();

    // 1. Batch-mark failed children (parent failed + requires_success)
    if !fail_child_ids.is_empty() {
        let failure_reason = format!("Required parent task {} failed", parent_id);
        let failed_ids: Vec<uuid::Uuid> = diesel::update(
            task_dsl::task.filter(
                task_dsl::id
                    .eq_any(&fail_child_ids)
                    .and(task_dsl::status.eq(StatusKind::Waiting)),
            ),
        )
        .set((
            task_dsl::status.eq(StatusKind::Failure),
            task_dsl::failure_reason.eq(&failure_reason),
            task_dsl::ended_at.eq(diesel::dsl::now),
        ))
        .returning(task_dsl::id)
        .get_results::<uuid::Uuid>(conn)
        .await?;

        for fid in &failed_ids {
            metrics::record_task_failed_by_dependency();
            log::info!(
                "Child task {} marked as failed due to required parent {} failure",
                fid,
                parent_id
            );
        }

        // Track direct failures
        all_cascade_failed.extend_from_slice(&failed_ids);

        // Recursively propagate failure to each actually-failed child's dependents
        for fid in &failed_ids {
            let recursive_failures =
                Box::pin(propagate_to_children(fid, &StatusKind::Failure, conn)).await?;
            all_cascade_failed.extend(recursive_failures);
        }
    }

    // 2. Batch-decrement counters for remaining children
    if !decrement_child_ids.is_empty() {
        // Decrement wait_finished for all remaining children
        diesel::update(
            task_dsl::task.filter(
                task_dsl::id
                    .eq_any(&decrement_child_ids)
                    .and(task_dsl::status.eq(StatusKind::Waiting)),
            ),
        )
        .set(task_dsl::wait_finished.eq(task_dsl::wait_finished - 1))
        .execute(conn)
        .await?;

        // Decrement wait_success only for children that require it
        if !decrement_success_child_ids.is_empty() {
            diesel::update(
                task_dsl::task.filter(
                    task_dsl::id
                        .eq_any(&decrement_success_child_ids)
                        .and(task_dsl::status.eq(StatusKind::Waiting)),
                ),
            )
            .set(task_dsl::wait_success.eq(task_dsl::wait_success - 1))
            .execute(conn)
            .await?;
        }

        // 3. Batch-transition to Pending where both counters reach 0
        let unblocked_ids: Vec<uuid::Uuid> = diesel::update(
            task_dsl::task.filter(
                task_dsl::id
                    .eq_any(&decrement_child_ids)
                    .and(task_dsl::status.eq(StatusKind::Waiting))
                    .and(task_dsl::wait_finished.eq(0))
                    .and(task_dsl::wait_success.eq(0)),
            ),
        )
        .set(task_dsl::status.eq(StatusKind::Pending))
        .returning(task_dsl::id)
        .get_results::<uuid::Uuid>(conn)
        .await?;

        for uid in &unblocked_ids {
            metrics::record_task_unblocked();
            metrics::record_status_transition("Waiting", "Pending");
            log::info!("Child task {} transitioned from Waiting to Pending", uid);
        }
    }

    Ok(all_cascade_failed)
}

// =============================================================================
// Dead-end ancestor cancellation
// =============================================================================

/// An ancestor task that was canceled by dead-end detection.
#[derive(Debug)]
pub(crate) struct CanceledAncestor {
    pub id: uuid::Uuid,
    /// True if the task was Running before cancellation (needs cancel webhook).
    pub was_running: bool,
}

/// Row returned by the writable CTE in `cancel_dead_end_ancestors`.
#[derive(diesel::QueryableByName, Debug)]
struct CanceledDeadEndRow {
    #[diesel(sql_type = diesel::sql_types::Uuid)]
    id: uuid::Uuid,
    #[diesel(sql_type = diesel::sql_types::Text)]
    prev_status: String,
    #[diesel(sql_type = diesel::sql_types::Bool)]
    is_barrier: bool,
}

/// Detect and cancel ancestor tasks whose ALL children are already terminal
/// (dead-end detection). Iterates upward through the DAG until no more
/// dead-end ancestors are found.
///
/// Must be called inside a transaction (same conn as the status change
/// that made children terminal).
///
/// Returns the list of canceled ancestors so callers can fire webhooks
/// after the transaction commits.
pub(crate) async fn cancel_dead_end_ancestors<'a>(
    newly_terminal_ids: &[uuid::Uuid],
    conn: &mut Conn<'a>,
) -> Result<Vec<CanceledAncestor>, DbError> {
    if newly_terminal_ids.is_empty() {
        return Ok(vec![]);
    }

    let mut all_canceled: Vec<CanceledAncestor> = Vec::new();
    let mut check_ids: Vec<uuid::Uuid> = newly_terminal_ids.to_vec();

    loop {
        if check_ids.is_empty() {
            break;
        }

        let canceled: Vec<CanceledDeadEndRow> = diesel::sql_query(
            "WITH candidates AS (
                SELECT DISTINCT l.parent_id
                FROM link l
                WHERE l.child_id = ANY($1)
            ),
            to_cancel AS (
                SELECT t.id, t.status::text AS prev_status, t.dead_end_barrier AS is_barrier
                FROM task t
                JOIN candidates c ON c.parent_id = t.id
                WHERE t.status NOT IN ('success', 'failure', 'canceled')
                  AND NOT EXISTS (
                      SELECT 1 FROM link l2
                      JOIN task c2 ON c2.id = l2.child_id
                      WHERE l2.parent_id = t.id
                        AND c2.status NOT IN ('success', 'failure', 'canceled')
                  )
                FOR UPDATE OF t SKIP LOCKED
            )
            UPDATE task
            SET status = 'canceled',
                failure_reason = 'All child tasks already terminated',
                ended_at = now(),
                last_updated = now()
            FROM to_cancel
            WHERE task.id = to_cancel.id
            RETURNING task.id, to_cancel.prev_status, to_cancel.is_barrier",
        )
        .bind::<diesel::sql_types::Array<diesel::sql_types::Uuid>, _>(&check_ids)
        .load::<CanceledDeadEndRow>(conn)
        .await?;

        if canceled.is_empty() {
            break;
        }

        // Next iteration: only propagate upward through non-barrier tasks
        check_ids = canceled
            .iter()
            .filter(|r| !r.is_barrier)
            .map(|r| r.id)
            .collect();

        for row in canceled {
            metrics::record_task_canceled_dead_end();
            metrics::record_status_transition(&row.prev_status, "Canceled");
            log::info!(
                "Dead-end detection: canceled ancestor task {} (was {}{})",
                row.id,
                row.prev_status,
                if row.is_barrier { ", barrier" } else { "" }
            );
            all_canceled.push(CanceledAncestor {
                id: row.id,
                was_running: row.prev_status == "running",
            });
        }
    }

    Ok(all_canceled)
}

pub async fn cancel_task<'a>(
    evaluator: &ActionExecutor,
    task_id: &uuid::Uuid,
    dead_end_enabled: bool,
    conn: &mut Conn<'a>,
) -> Result<(), DbError> {
    use crate::schema::task::dsl::*;
    let task_id = *task_id;

    // Phase 1: transaction â€” cancel + propagation + dead-end detection are atomic
    let (prev_status, cascade_failed, canceled_ancestors) =
        db_operation::run_in_transaction(conn, |conn| {
            Box::pin(async move {
                let t = task
                    .filter(id.eq(task_id))
                    .for_update()
                    .first::<Task>(conn)
                    .await?;

                match t.status {
                    StatusKind::Pending
                    | StatusKind::Paused
                    | StatusKind::Claimed
                    | StatusKind::Running => {}
                    _ => {
                        return Err(crate::error::TaskRunnerError::InvalidState {
                            message: "Invalid operation: cannot cancel task in this state".into(),
                        });
                    }
                }

                diesel::update(task.filter(id.eq(task_id)))
                    .set((
                        status.eq(StatusKind::Canceled),
                        ended_at.eq(diesel::dsl::now),
                        last_updated.eq(diesel::dsl::now),
                    ))
                    .execute(conn)
                    .await?;

                // Propagate cancellation to dependent children (inside tx)
                let cascade_failed =
                    propagate_to_children(&task_id, &StatusKind::Canceled, conn).await?;

                // Dead-end ancestor cancellation (inside tx)
                let canceled_ancestors = if dead_end_enabled {
                    let mut terminal_ids = vec![task_id];
                    terminal_ids.extend_from_slice(&cascade_failed);
                    cancel_dead_end_ancestors(&terminal_ids, conn).await?
                } else {
                    vec![]
                };

                Ok((t.status, cascade_failed, canceled_ancestors))
            })
        })
        .await?;

    // Phase 2: best-effort webhooks (outside transaction, errors logged not returned)
    if prev_status == StatusKind::Running {
        if let Err(e) = fire_cancel_webhooks(evaluator, &task_id, conn).await {
            log::error!(
                "Failed to fire cancel webhooks for task {}: {:?}",
                task_id,
                e
            );
        }
    }

    for child_id in &cascade_failed {
        if let Err(e) = fire_end_webhooks(evaluator, child_id, StatusKind::Failure, conn).await {
            log::error!(
                "Failed to fire on_failure webhooks for cascade-failed child {}: {:?}",
                child_id,
                e
            );
        }
    }

    fire_webhooks_for_canceled_ancestors(evaluator, &canceled_ancestors, conn).await;

    metrics::record_task_cancelled();
    Ok(())
}
